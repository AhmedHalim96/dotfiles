#compdef gallery-dl

# zsh completions for 'gallery-dl'
# automatically generated with http://github.com/RobSis/zsh-completion-generator
local arguments

arguments=(
  {-h,--help}'[print this help message and exit]'
  '--version[print program version and exit]'
  {-d,--dest}'[destination directory]'
  {-i,--input-file}'[download URLs found in FILE (- for stdin). More]'
  '--cookies[file to load additional cookies from]'
  '--proxy[use the specified proxy]'
  '--clear-cache[delete cached login sessions, cookies, etc. for]'
  {-q,--quiet}'[activate quiet mode]'
  {-v,--verbose}'[print various debugging information]'
  {-g,--get-urls}'[print URLs instead of downloading]'
  {-G,--resolve-urls}'[print URLs instead of downloading; resolve]'
  {-j,--dump-json}'[print JSON information]'
  {-s,--simulate}'[simulate data extraction; do not download anything]'
  {-E,--extractor-info}'[print extractor defaults and settings]'
  {-K,--list-keywords}'[print a list of available keywords and example]'
  '--list-modules[print a list of available extractor modules]'
  '--list-extractors[print a list of extractor classes with]'
  '--write-log[write logging output to FILE]'
  '--write-unsupported[write URLs, which get emitted by other extractors]'
  '--write-pages[write downloaded intermediary pages to files in]'
  {-r,--limit-rate}'[maximum download rate (e.g. 500k or 2.5M)]'
  {-R,--retries}'[maximum number of retries for failed HTTP requests]'
  '--http-timeout[timeout for HTTP connections (default: 30.0)]'
  '--sleep[number of seconds to sleep before each download]'
  '--filesize-min[do not download files smaller than SIZE (e.g. 500k]'
  '--filesize-max[do not download files larger than SIZE (e.g. 500k]'
  '--no-part[do not use .part files]'
  '--no-skip[do not skip downloads; overwrite existing files]'
  '--no-mtime[do not set file modification times according to]'
  '--no-download[do not download any files]'
  '--no-check-certificate[disable HTTPS certificate validation]'
  {-c,--config}'[additional configuration files]'
  {-o,--option}'[additional <key>=<value> option values]'
  '--ignore-config[do not read the default configuration files]'
  {-u,--username}'[username to login with]'
  {-p,--password}'[password belonging to the given username]'
  '--netrc[enable .netrc authentication data]'
  '--download-archive[record all downloaded files in the archive file]'
  {-A,--abort}'[stop current extractor run after N consecutive]'
  {-T,--terminate}'[stop current and parent extractor runs after N]'
  '--range[index-range(s) specifying which images to]'
  '--chapter-range[like --range, but applies to manga-chapters and]'
  '--filter[python expression controlling which images to]'
  '--filter[>= 1000 and rating in (s]'
  '--chapter-filter[like --filter, but applies to manga-chapters and]'
  '--zip[store downloaded files in a ZIP archive]'
  '--ugoira-conv[convert Pixiv Ugoira to WebM (requires FFmpeg)]'
  '--ugoira-conv-lossless[convert Pixiv Ugoira to WebM in VP9 lossless mode]'
  '--write-metadata[write metadata to separate JSON files]'
  '--write-tags[write image tags to separate text files]'
  '--mtime-from-date[set file modification times according to date]'
  '--exec[execute CMD for each downloaded file. Example:]'
  '--exec[{} {}.png && rm {}]'
  '--exec-after[execute CMD after all files were downloaded]'
  {-P,--postprocessor}'[activate the specified post processor]'
  '*:filename:_files'
)

_arguments -s $arguments
